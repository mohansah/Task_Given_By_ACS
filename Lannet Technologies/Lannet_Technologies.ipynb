{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lannet Technologies.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpybG4osSMDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dateutil import parser\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReV2w419SLmG",
        "colab_type": "text"
      },
      "source": [
        "# **Dummy dataset for Task 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3oUiU5IMASx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "b6e6ee9c-b45a-41fe-c296-1167116bd382"
      },
      "source": [
        "data1 = [[1, '02/17/2009', '20090317', '17 February, 2009'], [2, '20 March, 2010', '2014, Feb 17', '19/5/2009'], [3, '20/6/2025', '2014, Feb 20', '02/17/2009'], [4, '17/1/1998', '20190525', '20190217'], [5, '20090225', '17 February, 2020', '17 January, 1998'], [6, '2014, Feb 17', 'Feb172015', '27/9/1980'], [7, 'Feb202019', '02/17/2009', 'Feb052050']]\n",
        "dummy_dataframe1 = pd.DataFrame(data1, columns = ['Id', 'Date1', 'Date2', 'Date3'])\n",
        "dummy_dataframe1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Date1</th>\n",
              "      <th>Date2</th>\n",
              "      <th>Date3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>02/17/2009</td>\n",
              "      <td>20090317</td>\n",
              "      <td>17 February, 2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20 March, 2010</td>\n",
              "      <td>2014, Feb 17</td>\n",
              "      <td>19/5/2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>20/6/2025</td>\n",
              "      <td>2014, Feb 20</td>\n",
              "      <td>02/17/2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>17/1/1998</td>\n",
              "      <td>20190525</td>\n",
              "      <td>20190217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>20090225</td>\n",
              "      <td>17 February, 2020</td>\n",
              "      <td>17 January, 1998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2014, Feb 17</td>\n",
              "      <td>Feb172015</td>\n",
              "      <td>27/9/1980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Feb202019</td>\n",
              "      <td>02/17/2009</td>\n",
              "      <td>Feb052050</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id           Date1              Date2              Date3\n",
              "0   1      02/17/2009           20090317  17 February, 2009\n",
              "1   2  20 March, 2010       2014, Feb 17          19/5/2009\n",
              "2   3       20/6/2025       2014, Feb 20         02/17/2009\n",
              "3   4       17/1/1998           20190525           20190217\n",
              "4   5        20090225  17 February, 2020   17 January, 1998\n",
              "5   6    2014, Feb 17          Feb172015          27/9/1980\n",
              "6   7       Feb202019         02/17/2009          Feb052050"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBUafVjIBz2B",
        "colab_type": "text"
      },
      "source": [
        "# **Task 1.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS_jZPQYQcrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4aa7d7e2-9a3e-4ee8-bbdb-dfee6ff87655"
      },
      "source": [
        "# Function to identify which columns have date in them\n",
        "def identify_date_columns(dataframe):\n",
        "  Date_Column_Names = [] # List to store the columns which have date in them\n",
        "  for column in dataframe.columns:\n",
        "    try: # Try to get 4 digits value and store in the list\n",
        "      val = dataframe[column].str.extract(r'(\\d{4})')  # extracting 4 digits value from columns because year must have 4 digits value\n",
        "      if val.isnull().sum()[0] != len(val):  # Checking we got such values or not\n",
        "        Date_Column_Names.append(column)\n",
        "    except:  # If we did not get then simply pass the control to next column\n",
        "      pass\n",
        "  return Date_Column_Names\n",
        "\n",
        "Date_Column_Names = identify_date_columns(dummy_dataframe1)  # Function Call\n",
        "print(\"Columns which have date in them are\", Date_Column_Names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Columns which have date in them are ['Date1', 'Date2', 'Date3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl_dtNzRB6gZ",
        "colab_type": "text"
      },
      "source": [
        "# **Task 1.2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byt6BmlS2AXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "195e9c62-530a-4594-e99c-78f3075b03b0"
      },
      "source": [
        "# Funtion to convert string data type to datetime datatype\n",
        "def convert_string_into_date(dummy_dataframe1, Date_Column_Names):\n",
        "  for column in Date_Column_Names:\n",
        "    col = []\n",
        "    for date in dummy_dataframe1[column]:\n",
        "      col.append(parser.parse(date).date())  # Converts a string date to datatime date and append into list Col\n",
        "    dummy_dataframe1[\"Modified_\"+column] = col  # Adding a new column in dataframe\n",
        "  return dummy_dataframe1\n",
        "\n",
        "modify_dummy_dataframe1 = convert_string_into_date(dummy_dataframe1, Date_Column_Names)  # Function Call\n",
        "modify_dummy_dataframe1.drop([\"Id\", \"Date1\", \"Date2\", \"Date3\"], axis=1)  # Drops unwanted columns\n",
        "\n",
        "column_list = modify_dummy_dataframe1.columns\n",
        "for col1 in column_list:\n",
        "  for col2 in column_list:\n",
        "    if col1 is not col2:\n",
        "      modify_dummy_dataframe1[col1 + \" - \" + col2] = modify_dummy_dataframe1[col1] - modify_dummy_dataframe1[col2]  # Subtration of date from two columns taken at a time\n",
        "\n",
        "modify_dummy_dataframe1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modified_Date1</th>\n",
              "      <th>Modified_Date2</th>\n",
              "      <th>Modified_Date3</th>\n",
              "      <th>Modified_Date1 - Modified_Date2</th>\n",
              "      <th>Modified_Date1 - Modified_Date3</th>\n",
              "      <th>Modified_Date2 - Modified_Date1</th>\n",
              "      <th>Modified_Date2 - Modified_Date3</th>\n",
              "      <th>Modified_Date3 - Modified_Date1</th>\n",
              "      <th>Modified_Date3 - Modified_Date2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-02-17</td>\n",
              "      <td>2009-03-17</td>\n",
              "      <td>2009-02-17</td>\n",
              "      <td>-28 days</td>\n",
              "      <td>0 days</td>\n",
              "      <td>28 days</td>\n",
              "      <td>28 days</td>\n",
              "      <td>0 days</td>\n",
              "      <td>-28 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-03-20</td>\n",
              "      <td>2014-02-17</td>\n",
              "      <td>2009-05-19</td>\n",
              "      <td>-1430 days</td>\n",
              "      <td>305 days</td>\n",
              "      <td>1430 days</td>\n",
              "      <td>1735 days</td>\n",
              "      <td>-305 days</td>\n",
              "      <td>-1735 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-06-20</td>\n",
              "      <td>2014-02-20</td>\n",
              "      <td>2009-02-17</td>\n",
              "      <td>4138 days</td>\n",
              "      <td>5967 days</td>\n",
              "      <td>-4138 days</td>\n",
              "      <td>1829 days</td>\n",
              "      <td>-5967 days</td>\n",
              "      <td>-1829 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1998-01-17</td>\n",
              "      <td>2019-05-25</td>\n",
              "      <td>2019-02-17</td>\n",
              "      <td>-7798 days</td>\n",
              "      <td>-7701 days</td>\n",
              "      <td>7798 days</td>\n",
              "      <td>97 days</td>\n",
              "      <td>7701 days</td>\n",
              "      <td>-97 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-02-25</td>\n",
              "      <td>2020-02-17</td>\n",
              "      <td>1998-01-17</td>\n",
              "      <td>-4009 days</td>\n",
              "      <td>4057 days</td>\n",
              "      <td>4009 days</td>\n",
              "      <td>8066 days</td>\n",
              "      <td>-4057 days</td>\n",
              "      <td>-8066 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2014-02-17</td>\n",
              "      <td>2020-02-21</td>\n",
              "      <td>1980-09-27</td>\n",
              "      <td>-2195 days</td>\n",
              "      <td>12196 days</td>\n",
              "      <td>2195 days</td>\n",
              "      <td>14391 days</td>\n",
              "      <td>-12196 days</td>\n",
              "      <td>-14391 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2020-02-21</td>\n",
              "      <td>2009-02-17</td>\n",
              "      <td>2020-02-21</td>\n",
              "      <td>4021 days</td>\n",
              "      <td>0 days</td>\n",
              "      <td>-4021 days</td>\n",
              "      <td>-4021 days</td>\n",
              "      <td>0 days</td>\n",
              "      <td>4021 days</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Modified_Date1  ... Modified_Date3 - Modified_Date2\n",
              "0     2009-02-17  ...                        -28 days\n",
              "1     2010-03-20  ...                      -1735 days\n",
              "2     2025-06-20  ...                      -1829 days\n",
              "3     1998-01-17  ...                        -97 days\n",
              "4     2009-02-25  ...                      -8066 days\n",
              "5     2014-02-17  ...                     -14391 days\n",
              "6     2020-02-21  ...                       4021 days\n",
              "\n",
              "[7 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT39ilxYCBm5",
        "colab_type": "text"
      },
      "source": [
        "# **Task 1.3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JlBmMkjBPc_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "398f9948-32e6-4b8b-adf4-06b3ef18c880"
      },
      "source": [
        "modify_dummy_dataframe1.drop(['Modified_Date1', 'Modified_Date2', 'Modified_Date3'], axis=1) # Drops unwanted columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modified_Date1 - Modified_Date2</th>\n",
              "      <th>Modified_Date1 - Modified_Date3</th>\n",
              "      <th>Modified_Date2 - Modified_Date1</th>\n",
              "      <th>Modified_Date2 - Modified_Date3</th>\n",
              "      <th>Modified_Date3 - Modified_Date1</th>\n",
              "      <th>Modified_Date3 - Modified_Date2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-28 days</td>\n",
              "      <td>0 days</td>\n",
              "      <td>28 days</td>\n",
              "      <td>28 days</td>\n",
              "      <td>0 days</td>\n",
              "      <td>-28 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1430 days</td>\n",
              "      <td>305 days</td>\n",
              "      <td>1430 days</td>\n",
              "      <td>1735 days</td>\n",
              "      <td>-305 days</td>\n",
              "      <td>-1735 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4138 days</td>\n",
              "      <td>5967 days</td>\n",
              "      <td>-4138 days</td>\n",
              "      <td>1829 days</td>\n",
              "      <td>-5967 days</td>\n",
              "      <td>-1829 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-7798 days</td>\n",
              "      <td>-7701 days</td>\n",
              "      <td>7798 days</td>\n",
              "      <td>97 days</td>\n",
              "      <td>7701 days</td>\n",
              "      <td>-97 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4009 days</td>\n",
              "      <td>4057 days</td>\n",
              "      <td>4009 days</td>\n",
              "      <td>8066 days</td>\n",
              "      <td>-4057 days</td>\n",
              "      <td>-8066 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-2195 days</td>\n",
              "      <td>12196 days</td>\n",
              "      <td>2195 days</td>\n",
              "      <td>14391 days</td>\n",
              "      <td>-12196 days</td>\n",
              "      <td>-14391 days</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4021 days</td>\n",
              "      <td>0 days</td>\n",
              "      <td>-4021 days</td>\n",
              "      <td>-4021 days</td>\n",
              "      <td>0 days</td>\n",
              "      <td>4021 days</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Modified_Date1 - Modified_Date2  ... Modified_Date3 - Modified_Date2\n",
              "0                        -28 days  ...                        -28 days\n",
              "1                      -1430 days  ...                      -1735 days\n",
              "2                       4138 days  ...                      -1829 days\n",
              "3                      -7798 days  ...                        -97 days\n",
              "4                      -4009 days  ...                      -8066 days\n",
              "5                      -2195 days  ...                     -14391 days\n",
              "6                       4021 days  ...                       4021 days\n",
              "\n",
              "[7 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTXCaybwMYUT",
        "colab_type": "text"
      },
      "source": [
        "# **Dummy dataset for Task 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oskza8EeOc9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "895e871b-4f0a-4e97-c8db-1321913db98a"
      },
      "source": [
        "data2 = [[10, 11, 13, 15 , 17], [45, 24, 89, 74, 62], [12, 24, 36, 48, 60]]\n",
        "dummy_dataframe2 = pd.DataFrame(data2, columns=[\"v1\",\"v2\",\"v3\",\"v4\",\"v5\"])\n",
        "dummy_dataframe2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45</td>\n",
              "      <td>24</td>\n",
              "      <td>89</td>\n",
              "      <td>74</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>36</td>\n",
              "      <td>48</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   v1  v2  v3  v4  v5\n",
              "0  10  11  13  15  17\n",
              "1  45  24  89  74  62\n",
              "2  12  24  36  48  60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oYdH_nmMvfa",
        "colab_type": "text"
      },
      "source": [
        "## **Task 2.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O31oGmQHIAwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "6dc69db3-c30c-4138-9cb8-675643a6c990"
      },
      "source": [
        "# Calculating Pearson correlation\n",
        "dummy_dataframe2.corr()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>v1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.543413</td>\n",
              "      <td>0.969251</td>\n",
              "      <td>0.857146</td>\n",
              "      <td>0.576012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v2</th>\n",
              "      <td>0.543413</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.733273</td>\n",
              "      <td>0.898170</td>\n",
              "      <td>0.999226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v3</th>\n",
              "      <td>0.969251</td>\n",
              "      <td>0.733273</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.957536</td>\n",
              "      <td>0.759450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v4</th>\n",
              "      <td>0.857146</td>\n",
              "      <td>0.898170</td>\n",
              "      <td>0.957536</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.914768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>v5</th>\n",
              "      <td>0.576012</td>\n",
              "      <td>0.999226</td>\n",
              "      <td>0.759450</td>\n",
              "      <td>0.914768</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          v1        v2        v3        v4        v5\n",
              "v1  1.000000  0.543413  0.969251  0.857146  0.576012\n",
              "v2  0.543413  1.000000  0.733273  0.898170  0.999226\n",
              "v3  0.969251  0.733273  1.000000  0.957536  0.759450\n",
              "v4  0.857146  0.898170  0.957536  1.000000  0.914768\n",
              "v5  0.576012  0.999226  0.759450  0.914768  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9X3Q2H9ICDQ",
        "colab_type": "text"
      },
      "source": [
        "# **Task 3.1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI7O5SuFE_Ma",
        "colab_type": "text"
      },
      "source": [
        "# Imputation\n",
        "Data scientists are expected to come up with an appropriate strategy to handle missing data during, both, model training/testing phase and also model prediction time (runtime). This is called Data Imputation.\n",
        "\n",
        "Some imputation techniques which could be used to replace missing data with appropriate values during model prediction time\n",
        "1. Input data validation\n",
        "2. Predicted value imputation\n",
        "3. Distribution-based imputation\n",
        "4. Unique value imputation\n",
        "5. Reduced feature models\n",
        "\n",
        "## Input Data Validation\n",
        "Before sending the data to the model, the consumer/caller program validates if data for all the features are present. If the data for all of the features are not present, the caller program doesn’t invoke the model at all and takes on some value or show exceptions. For beginners, this could be a technique to start with. If this technique is used during training model training/testing phase, it could result in model bias.\n",
        "\n",
        "## Predicted Value Imputation (PVI)\n",
        "In this technique, one of the following methods is followed to impute missing data and invoke the model appropriately to get the predictions:\n",
        "\n",
        "Impute with mean or mode value: In place of missing value, mean or mode value is taken appropriately for continuous and categorical data respectively.\n",
        "Impute with predicted value: Another technique is understanding/learning the relationship between missing data and other features value in other test instances where data were found for feature representing missing data, and appropriately predict the missing data based on the value of other features for the instances where data is found to be missing. One could, however, argue that if a feature value can be estimated using other feature values, isn’t it the case of correlates and thus the feature could be imputed. One needs to watch out for feature imputability scenarios.\n",
        "\n",
        "## Distribution-based Imputation (DBI)\n",
        "In this technique, for the (estimated) distribution over the values of an attribute/feature (for which data is missing), one may estimate the expected distribution of the target variable (weighting the possible assignments of the missing values). The final prediction could be weighted average (mean or mode) value of all the prediction. This strategy is common for applying classification trees in AI research and practice. This technique is fundamentally different from predicted value imputation because it combines the classifications across the distribution of a feature’s possible values, rather than merely making the classification based on its most likely value.\n",
        "\n",
        "## Unique Value Imputation \n",
        "In this technique, a unique value is imputed in place of missing values. This technique is recommended when it can be determined if the data is generally found to be missing for a particular label/class value and, this dependence is found during model training/testing phase. One of the techniques used for imputing missing data with unique value is randomly selecting similar records. This is also termed as hot-deck cold deck imputation technique. The random selection for missing data imputation could be instances such as a selection of last observation (also termed Last observation carried forward – LOCF).\n",
        "\n",
        "## Reduced Feature Models\n",
        "In this technique, different models are built with the different set of features with the idea that appropriate models with only those set of features are used for making predictions for which the data is available. This is against applying imputation to missing data using one of the above techniques. For example, let’s say that a model is built with feature A, B, AB, C, D. As part of analysis it is found out that most of the time, data related to feature D would be missing. Thus, using the reduced feature modelling technique, another model using features A, B, AB, and C is built. In production, both the models get deployed and in case the data is found to be missing data for feature D, the model trained with features A, B, AB and C is used or else, the model with all features including feature D is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwqoP9V3DI8V",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection\n",
        "Feature Selection is a technique which selects the most relevant features from the original dataset.\n",
        "\n",
        "Top reasons to use feature selection are:\n",
        "•\tIt enables the machine learning algorithm to train faster.\n",
        "•\tIt reduces the complexity of a model and makes it easier to interpret.\n",
        "•\tIt improves the accuracy of a model if the right subset is chosen.\n",
        "•\tIt reduces overfitting.\n",
        "\n",
        "Various methodologies and techniques that you can use to subset your feature space and help your models perform better and efficiently. \n",
        "\n",
        "## 1. Filter Methods\n",
        " \n",
        "Filter methods are generally used as a preprocessing step. The selection of features is independent of any machine learning algorithms.\n",
        " \n",
        "•\tPearson’s Correlation: It is used as a measure for quantifying linear dependence between two continuous variables X and Y. Its value varies from -1 to +1. Pearson’s correlation is given as:\n",
        " \n",
        "•\tLDA: Linear discriminant analysis is used to find a linear combination of features that characterizes or separates two or more classes (or levels) of a categorical variable.\n",
        "\n",
        "•\tANOVA: ANOVA stands for Analysis of variance. It is similar to LDA except for the fact that it is operated using one or more categorical independent features and one continuous dependent feature. It provides a statistical test of whether the means of several groups are equal or not.\n",
        "\n",
        "•\tChi-Square: It is a is a statistical test applied to the groups of categorical features to evaluate the likelihood of correlation or association between them using their frequency distribution.\n",
        "\n",
        "Note: Filter methods do not remove multicollinearity. So, you must deal with multicollinearity of features as well before training models for your data.\n",
        "\n",
        "## 2. Wrapper Methods\n",
        " \n",
        "In wrapper methods, we try to use a subset of features and train a model using them. Based on the inferences that we draw from the previous model, we decide to add or remove features from your subset. The problem is essentially reduced to a search problem. These methods are usually computationally very expensive.\n",
        "Some common examples of wrapper methods are forward feature selection, backward feature elimination, recursive feature elimination, etc.\n",
        "\n",
        "•\tForward Selection: Forward selection is an iterative method in which we start with having no feature in the model. In each iteration, we keep adding the feature which best improves our model till an addition of a new variable does not improve the performance of the model.\n",
        "\n",
        "•\tBackward Elimination: In backward elimination, we start with all the features and removes the least significant feature at each iteration which improves the performance of the model. We repeat this until no improvement is observed on removal of features.\n",
        "\n",
        "•\tRecursive Feature elimination: It is a greedy optimization algorithm which aims to find the best performing feature subset. It repeatedly creates models and keeps aside the best or the worst performing feature at each iteration. It constructs the next model with the left features until all the features are exhausted. It then ranks the features based on the order of their elimination.\n",
        "One of the best ways for implementing feature selection with wrapper methods is to use Boruta package that finds the importance of a feature by creating shadow features.\n",
        "\n",
        "\n",
        "## 3. Embedded Methods\n",
        " \n",
        "Embedded methods combine the qualities’ of filter and wrapper methods. It’s implemented by algorithms that have their own built-in feature selection methods.\n",
        "\n",
        "Some of the most popular examples of these methods are LASSO and RIDGE regression which have inbuilt penalization functions to reduce over fitting.\n",
        "\n",
        "•\tLasso regression performs L1 regularization which adds penalty equivalent to absolute value of the magnitude of coefficients.\n",
        "\n",
        "•\tRidge regression performs L2 regularization which adds penalty equivalent to square of the magnitude of coefficients.\n",
        "\n",
        "Other examples of embedded methods are Regularized trees, Memetic algorithm, Random multinomial logit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfv5QmQMF1Om",
        "colab_type": "text"
      },
      "source": [
        "# Normalization\n",
        "Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information. Normalization is also required for some algorithms to model the data correctly.\n",
        "\n",
        "Some methods for Normalization\n",
        "\n",
        "1. Zscore: Converts all values to a z-score.\n",
        "2. MinMax: The min-max normalizer linearly rescales every feature to the [0,1] interval.\n",
        "3. Logistic: The values in the column are transformed using the following formula:\n",
        "4. LogNormal: This option converts all values to a lognormal scale.\n",
        "5. TanH: All values are converted to a hyperbolic tangent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w_l_EeVItP4",
        "colab_type": "text"
      },
      "source": [
        "# **Task 4.1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZyO2yGAIxZi",
        "colab_type": "text"
      },
      "source": [
        "1. Use some of Python’s “speedup” applications\n",
        "\n",
        "Python has developed a reputation as a solid, high-performance language. Lots has been done in recent years to get to this point. The PyPy project aims to speed up Python as a whole (and is doing a great job of it). And Numba is another tool that can offer amazing speedups by implementing high performance functions written directly in Python.\n",
        "\n",
        "2. Using generators & sorting with keys\n",
        "\n",
        "Generators are helpful in memory optimization because they allow you to create a function that returns one item at a time rather than all the items at once. A good example would be when you’re creating a large list of numbers and adding them together.\n",
        "\n",
        "Also, when you’re sorting items in a list, be sure to use keys and the default sort() method whenever possible. \n",
        "\n",
        "\n",
        "3. Using the latest releases of Python\n",
        "\n",
        "Python is maintained through a community of developers who are committed to keeping the software current and robust. Each new release of the language is technically going to be faster and more optimized than before, so it’s a good idea to plan your move. Just be sure that your favorite supporting libraries are compatible with the newest versions.\n",
        "\n",
        "4. Avoid unwanted loops\n",
        "\n",
        "The consensus is out that too much looping in any programming language is not a good thing, and puts unnecessary strain on your server. Some simple tweaks like storing the length of an array in a different variable instead of making it read the length at every iteration of the loop, can go a long way to optimizing your code and ensuring things run much more efficiently. Also, try refactoring your code to use intersections and unions.\n",
        "\n",
        "5. Try out multiple coding approaches\n",
        "\n",
        "It’s typical to employ the same general coding techniques throughout your application. But why not try a little experimentation to see if one technique is better or more optimal than another. This will help keep you sharp and innovative in your approaches to coding, no matter what language you’re working in. By learning to “think outside the box” you’ll creatively apply new coding techniques to obtain faster results with your applications.\n",
        "\n",
        "6. Keep Python code small and light\n",
        "\n",
        "It is often the case in programming that simplest is fastest. In this day and age performance is critical and it’s especially important to keep your Python code as compact as possible to reduce latency and speed things up. One article provides some organizing questions that are worth asking in the development stage: “Do we really need this module?”, “Why are we using this framework? Is it worth the overhead?”, “Can we do this in a simpler way?”\n",
        "\n",
        " \n",
        "\n",
        "7. Cloud-based application performance monitoring\n",
        "\n",
        "Your Python-based applications and websites are only as good as the performance of your infrastructure, which is why application performance is too important to leave to chance. What this requires is the best-in-class monitoring capability for all your IT systems. That’s exactly what you’ll find in Monitis. As the trusted leader in this market, Monitis offers a 24/7 cloud-based monitoring platform for websites, servers, applications, and networks. Through an easy to follow and intuitive web-interface, Monitis tracks all of your business-critical applications to ensure everything is running optimally and that you’re alerted to issues long before your customers are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDShZTkyMcck",
        "colab_type": "text"
      },
      "source": [
        "# **Dummy dataset for Task 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdP-ZoFPQc8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "0d426dd0-3bd4-421c-ddf6-a090c3223201"
      },
      "source": [
        "data5 = [['Bob', '6th Street,Sterling VA 20165-7513'], ['John', '7th Street, Wilmington NC 28411'], ['Mohan', '7th Street, Wilmington, 847226'], ['Sonu', '6th Street,Sterling VA']]\n",
        "dummy_dataframe5 = pd.DataFrame(data5, columns = ['Name', 'Address'])\n",
        "dummy_dataframe5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Address</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bob</td>\n",
              "      <td>6th Street,Sterling VA 20165-7513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John</td>\n",
              "      <td>7th Street, Wilmington NC 28411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mohan</td>\n",
              "      <td>7th Street, Wilmington, 847226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonu</td>\n",
              "      <td>6th Street,Sterling VA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Name                            Address\n",
              "0    Bob  6th Street,Sterling VA 20165-7513\n",
              "1   John    7th Street, Wilmington NC 28411\n",
              "2  Mohan     7th Street, Wilmington, 847226\n",
              "3   Sonu             6th Street,Sterling VA"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJejsTMpMpmr",
        "colab_type": "text"
      },
      "source": [
        "## **Task 5.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHZ9gmwWR960",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "a8a2aecf-aa71-4e6c-e802-13783a8658ec"
      },
      "source": [
        "dummy_dataframe5['Zip'] = dummy_dataframe5['Address'].str.extract(r'(\\d{5})') # Extracting the 5 digit value from address and adding a new column Zip into dataframe, NaN means address does not contain zip code\n",
        "dummy_dataframe5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Address</th>\n",
              "      <th>Zip</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bob</td>\n",
              "      <td>123 6th Street,Sterling VA 20165-7513</td>\n",
              "      <td>20165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John</td>\n",
              "      <td>567 7th Street, Wilmington NC 28411</td>\n",
              "      <td>28411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mohan</td>\n",
              "      <td>7th Street, Wilmington, 847226</td>\n",
              "      <td>84722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonu</td>\n",
              "      <td>6th Street,Sterling VA</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Name                                Address    Zip\n",
              "0    Bob  123 6th Street,Sterling VA 20165-7513  20165\n",
              "1   John    567 7th Street, Wilmington NC 28411  28411\n",
              "2  Mohan         7th Street, Wilmington, 847226  84722\n",
              "3   Sonu                 6th Street,Sterling VA    NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEeA8O1_Me5B",
        "colab_type": "text"
      },
      "source": [
        "# **Dummy dataset for Task 6**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQvv5O4hMO7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "4fcb7599-05e9-4e1c-bd7c-d5e78156e1f2"
      },
      "source": [
        "data6 = [[2, \"Susil\", 0, \"Kumar\"], [1, \"Mohan\", 0, \"Kumar\"], [2, \"Sohan\", 1, \"Sah\"], [3, \"Sohan\", 0, \"Kumar\"], [1, \"Sunil\", 1, \"Mahto\"], [3, \"Mohan\", 1, \"Sah\"]]\n",
        "dummy_dataframe6 = pd.DataFrame(data6, columns = [\"Col1\", \"Col2\", \"Col3\", \"Col4\"])\n",
        "dummy_dataframe6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Col1</th>\n",
              "      <th>Col2</th>\n",
              "      <th>Col3</th>\n",
              "      <th>Col4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Susil</td>\n",
              "      <td>0</td>\n",
              "      <td>Kumar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Mohan</td>\n",
              "      <td>0</td>\n",
              "      <td>Kumar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sohan</td>\n",
              "      <td>1</td>\n",
              "      <td>Sah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Sohan</td>\n",
              "      <td>0</td>\n",
              "      <td>Kumar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Sunil</td>\n",
              "      <td>1</td>\n",
              "      <td>Mahto</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>Mohan</td>\n",
              "      <td>1</td>\n",
              "      <td>Sah</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Col1   Col2  Col3   Col4\n",
              "0     2  Susil     0  Kumar\n",
              "1     1  Mohan     0  Kumar\n",
              "2     2  Sohan     1    Sah\n",
              "3     3  Sohan     0  Kumar\n",
              "4     1  Sunil     1  Mahto\n",
              "5     3  Mohan     1    Sah"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO5VuT2vMlUl",
        "colab_type": "text"
      },
      "source": [
        "## **Task 6.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pywdw6WFN-IE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "25c2630b-8329-4be1-e592-6e6617c076c8"
      },
      "source": [
        "# Function to identify datatype of columns and typos present in columns\n",
        "def address_typos(dataframe):\n",
        "  for column in dataframe.columns:\n",
        "    print(\"For column\",column,\"Data type is\",dataframe[column].dtype,\"Typos are\",dataframe[column].unique()) # Using unique we can find the typos of a column\n",
        "\n",
        "address_typos(dummy_dataframe6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For column Col1 Data type is int64 Typos are [2 1 3]\n",
            "For column Col2 Data type is object Typos are ['Susil' 'Mohan' 'Sohan' 'Sunil']\n",
            "For column Col3 Data type is int64 Typos are [0 1]\n",
            "For column Col4 Data type is object Typos are ['Kumar' 'Sah' 'Mahto']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}